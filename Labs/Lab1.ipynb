{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANLE1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "12ADj2Gn2FlXX1i2MPlpgQThkzj26ubK9",
      "authorship_tag": "ABX9TyMM1onszUN6IzauM5KsPnOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashmcmn/NLE_Notes/blob/main/Labs/Lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkf5VUO1MlEK"
      },
      "source": [
        "!gdown --id '1-Q-03PBKtPZHYYuQMq_RcgaRsuDtdtYW'\n",
        "!gdown --id '1Y8IckbKz9Xy1lBY9QndSoVwcj-PPGdg3'\n",
        "!unzip 'wk1labresources.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkZ790LxNKyj"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('wordnet_ic')\n",
        "\n",
        "import operator\n",
        "from nltk.corpus import wordnet as wn, wordnet_ic as wn_ic, lin_thesaurus as lin\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "from scipy.stats import spearmanr, linregress\n",
        "\n",
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFDst75iORUa"
      },
      "source": [
        "wn.synsets(\"book\")\n",
        "wn.synsets(\"book\",wn.NOUN)\n",
        "synsetA=wn.synsets(\"book\",wn.NOUN)[0]\n",
        "synsetA.definition()\n",
        "synsetA.hyponyms()\n",
        "synsetA.hypernyms()\n",
        "synsetB=wn.synsets(\"book\",wn.NOUN)[1]\n",
        "synsetA.path_similarity(synsetB)\n",
        "brown_ic=wn_ic.ic(\"ic-brown.dat\")\n",
        "synsetA.res_similarity(synsetB,brown_ic)\n",
        "synsetA.lin_similarity(synsetB,brown_ic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXwU67de5yJH"
      },
      "source": [
        "# 2.1 Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqHiWB7_560N"
      },
      "source": [
        "1. Write a function to return the path similarity of two nouns. Remember this is the maximum\n",
        "similarity of all of the possible pairings of the two nouns. Make sure you test it. For (chicken,car)\n",
        "the correct answer is 0.0909 (3sf).\n",
        "\n",
        "2. Generalise it so that you have an extra (optional) parameter which you use to select the WordNet\n",
        "similarity measure e.g., res similarity and lin similarity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1lfssnaOByO"
      },
      "source": [
        "def noun_similarity(w1, w2, measure_fn = 'path', ic = None):\n",
        "  synset1 = wn.synsets(w1, wn.NOUN)\n",
        "  synset2 = wn.synsets(w2, wn.NOUN)\n",
        "  mx = -9999\n",
        "  \n",
        "  for sense1 in synset1:\n",
        "    for sense2 in synset2:\n",
        "      if measure_fn == 'path':\n",
        "        s = sense1.path_similarity(sense2)\n",
        "      elif measure_fn == 'res':\n",
        "        s = sense1.res_similarity(sense2, ic)\n",
        "      elif measure_fn == 'lch':\n",
        "        s = sense1.lch_similarity(sense2, ic)\n",
        "      elif measure_fn == 'wup':\n",
        "        s = sense1.wup_similarity(sense2, ic)\n",
        "      elif measure_fn == 'jcn':\n",
        "        s = sense1.jcn_similarity(sense2, ic)\n",
        "      elif measure_fn == 'lin':\n",
        "        s = sense1.lin_similarity(sense2, ic)\n",
        "      mx = max(mx, s)\n",
        "\n",
        "  return mx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvWDwYvyOug3"
      },
      "source": [
        "noun_similarity('football', 'cake', 'path', brown_ic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNIjB7zH6SRC"
      },
      "source": [
        "# 3.1 Tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi6AiK0R6Uwp"
      },
      "source": [
        "1. Read in mcdata.csv and store it in an appropriate format so that you can obtain a list of pairs of\n",
        "nouns and the score associated with each pair.\n",
        "2. Calculate the similarity score for each pair of nouns using at least 2 semantic similarity measures.\n",
        "3. Correlate each of the calculated sets of scores with each other and with the human judgements (I\n",
        "suggest you use scipy.stats.spearmanr() or pandas for this).\n",
        "4. What do you conclude?\n",
        "\n",
        "The Miller & Charles human judgements correlate most with the Jiang-Conrath Similarity. A score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer and that of the two input Synsets. The relationship is given by the equation 1 / (IC(s1) + IC(s2) - 2 * IC(lcs)). Leacock-Chodorow Similarity correlates highly with Wu-Palmer Similarity, all measures correlate with each other to an extent with the lowest Spearman's rank correlation coefficient being 0.72 between human judgement and Leacock-Chodorow Similarity. JCN seemes to get its high human correlation from the fact that it can produce very low scores that match with some of the very low human scores, where as other measures seem unlikely to produce scores under 0.1. This is demonstrated well in the scatter plots in section 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpGt-iVMTxJy"
      },
      "source": [
        "df = pd.read_csv('wk1labresources/mcdata.csv', names=['Word1', 'Word2', 'Human'])\n",
        "\n",
        "df[3] = [noun_similarity(row['Word1'], row['Word2'], 'res', brown_ic) for index, row in df.iterrows()]\n",
        "df[4] = [noun_similarity(row['Word1'], row['Word2'], 'lch', brown_ic) for index, row in df.iterrows()]\n",
        "df[5] = [noun_similarity(row['Word1'], row['Word2'], 'wup', brown_ic) for index, row in df.iterrows()]\n",
        "df[6] = [noun_similarity(row['Word1'], row['Word2'], 'jcn', brown_ic) for index, row in df.iterrows()]\n",
        "df[7] = [noun_similarity(row['Word1'], row['Word2'], 'lin', brown_ic) for index, row in df.iterrows()]\n",
        "df.rename(columns={3: 'res', 4: 'lch', 5: 'wup', 6: 'jcn', 7: 'lin'}, inplace=True)\n",
        "\n",
        "\n",
        "df.corr(method='spearman')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZO5UWPSC0zT"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku2AFNE06oX4"
      },
      "source": [
        "# 4.1 Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnUrfcY-6qQJ"
      },
      "source": [
        "1. Repeat the tasks in Section 3 using similarity scores from the word2vec model. Make sure you\n",
        "correlate the word2vec similarities with the human synonymy judgements and the wordnet similarity\n",
        "scores.\n",
        "2. What do you conclude?\n",
        "\n",
        "Word2Vec produces the highest correlation with human judgements bar the Jiang-Conrath Similarity. It's interesting to see that SRCC suggests minimal correlation between Word2Vec and the WordNet measures, even though the measures all correlate to the human judgement. This suggests that words with dissilimar similarity scores from WordNet are more similar using Word2Vec. However, it is difficult to compare any of these measures as they are due to the difference in their scaling. For example, wup, lin and Word2Vec produces scores between 0 and 1, whereas res, lch and jcn produce scores beyond 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyfrnCuYZNXH"
      },
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2KjlhBqdCKq"
      },
      "source": [
        "df[8] = [word2vec.similarity(row['Word1'], row['Word2']) for index, row in df.iterrows()]\n",
        "df.rename(columns={8: 'w2v'}, inplace=True)\n",
        "\n",
        "df.corr(method='spearman')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL1EYoxS_0Su"
      },
      "source": [
        "df[df['jcn'] > 100] = np.NaN # get rid of jcn values of e^300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Klcr-pIBWqf"
      },
      "source": [
        "# 5 Extension: Significance Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grhv815wBbBf"
      },
      "source": [
        "How much better does one measure need to be than another in order for it to be a significant difference?\n",
        "If a different set of pairs of words had been chosen, how likely is it that you would have come to a\n",
        "different conclusion? This is a very hard question to answer conclusively but most notions of statistical\n",
        "significance are based on the size of the sample (bigger sample more likely to be significant) and the\n",
        "amount of variance in the sample (less variance implies more likely to be significant). Here we are going\n",
        "to attempt to estimate the significance of your results from Section 3.\n",
        "1. For each of the similarity measures you have considered, plot a scatter graph of word net-based\n",
        "similarity scores against human semantic judgments. You could use the scatter function from\n",
        "matplotlib or pandas for this. Make sure you add labels to the x and y axes and a title.\n",
        "2. Add a text box to the graph to display the correlation coefficient and the p-value. What does this\n",
        "p-value mean?\n",
        "\n",
        "The values are very low indicating minimal statistical significance. This is likely because of the small sample size.\n",
        "\n",
        "3. Calculate the regression line (i.e., the line of best fit) for each data set and display it on the graph.\n",
        "You can use scipy.stats.linregress() to calculate the regression line. Does this function return\n",
        "the same correlation coefficient as scipy.stats.spearmanr()?\n",
        "\n",
        "No the correlation coefficients are different, it looks as though the linear regression method produces similar results to pearson's correlational method.\n",
        "\n",
        "4. One way to get a handle on whether the differences between two correlation coefficients are significant\n",
        "is to construct 95% confidence intervals for those coefficients. A p% confidence interval should\n",
        "capture the true value p% of the time. Therefore if the confidence intervals don’t overlap, there is\n",
        "a very small chance (< 0.0252\n",
        ") that the one which has been observed to be the best is not the best.\n",
        "Common ways to construct confidence intervals include the Central Limit Theorem, cross-validation\n",
        "and bootstrapping. Here we will use bootstrapping2.\n",
        "In order to construct a 95% confidence interval of the correlation coefficient for n points.\n",
        "\n",
        "*   Take a random sample of n points (with replacement!).\n",
        "*   Calculate the correlation coefficient for the random sample.\n",
        "*   Repeat at least 100 times (1000 or 10000 would be better).\n",
        "*   Find the 2.5% and 97.5% percentiles from the list of correlation coefficients found for the different random samples. This is your 95% confidence interval.\n",
        "\n",
        "Construct 95% confidence intervals for at least 2 of the correlation coefficients. What do you conclude about the differences?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK2mfrF7BsVf"
      },
      "source": [
        "for measure in ['res', 'lch', 'wup', 'jcn', 'lin']:\n",
        "  fig, ax = plt.subplots()\n",
        "  \n",
        "  ax.scatter(x=df['Human'], y=df[measure])\n",
        "  ax.set_xlabel('Human')\n",
        "  ax.set_ylabel(measure)\n",
        "  ax.set_title('Human vs {}'.format(measure))\n",
        "\n",
        "  n = 10\n",
        "  interval = 0.95\n",
        "  srccs = []\n",
        "  for i in range(1000):\n",
        "    sample = df.sample(n)\n",
        "    srcc = sample['Human'].corr(sample[measure], method='spearman')\n",
        "    srccs.append(srcc)\n",
        "  srccs = pd.DataFrame(srccs)\n",
        "\n",
        "  res = linregress(df['Human'],df[measure])\n",
        "  ax.plot(df['Human'], res.intercept + res.slope*df['Human'], 'r', label='fitted line')\n",
        "  \n",
        "  textstr = r'$\\rho={:.2f}$''\\np-value={:.2e}\\nconf({}): {:.2f}<x<{:.2f}'.format(df['Human'].corr(df[measure], method='spearman'), spearmanr(df['Human'],df[measure])[1], interval, srccs.quantile((1-interval)/2)[0], srccs.quantile(1-(1-interval)/2)[0])\n",
        "\n",
        "  props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "\n",
        "  ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
        "        verticalalignment='top', bbox=props)\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}